# 某漫画网站的爬虫

## 更新

3.0版本

由于之前漫画质量不是很好，翻译整合了好几家，繁简都有，而且存在章节错位，于是把download_1.0and2.0.py进行了换源重置，并和pic_to_url.py的功能做了整合，成为download_3.0.py

后来发现换源后有几章网站那边图片404，可以通过1.0、2.0版本的成果互补。404check.py用于检测哪几章崩了，远离时检测目录中是否有md5值重复的图片，有时会误伤(比如网站抽风一张图放两次)。

其他没写的思路：若404图片都是一张（确实都是一张），可以检测特定哈希值。

## 局限性

后来发现3.0程序仍然不具备爬同网站其他内容的通用性，原因在于：

程序默认所有章节号都是整数，而章节号在html中提取，在漫画Dr.STONE中所有章节格式均为“第x话”，提取很方便。但很多漫画的章节号存在许多非整数，且格式参差不齐。

解决方案为，把章节号-url映射表格式由dict[int, str]改为dict[str, str]，在爬取所有章节时，采用遍历字典的方式，而非整数枚举。但目前没有需求，不会改了。

## 历史内容

这是2.0版本 在1.0版本上做过一些修改，代码有冗余。

1.0： 根据相邻章节url关系设计爬虫逻辑，存在无序章节扰乱。

2.0：先爬上级目录做出章节-url映射表，查表定位。

附加:由于看图片需要手动翻页和调整大小，太麻烦了，于是把它们做成了html。

